{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vae.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/savadikarc/vae/blob/master/vae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai21O7a0CS2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpaMgh9cGsRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_path = '/content/drive/My Drive/<PATH_TO_SAVE_TO>/'\n",
        "!ls /content/drive/My\\ Drive/DL_ML/VAE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHu3L_OQUYRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PyTorch - \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# NumPy, standard\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Visualization\n",
        "import imageio\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgAh-TN3Z3ud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVwt1OB3kw10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "latent_size = 2\n",
        "hidden_size = 1024\n",
        "base_filters = 8\n",
        "batch_size = 2048\n",
        "EPOCHS = 1000\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IexwMpwgg4Db",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderFC(nn.Module):\n",
        "    \n",
        "    def __init__(self, latent_size=10):\n",
        "        \n",
        "        super(EncoderFC, self).__init__()\n",
        "        self.latent_size = latent_size\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(784, hidden_size, bias=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(hidden_size, hidden_size, bias=True),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        \n",
        "        self.linear_mu = nn.Linear(hidden_size, latent_size)\n",
        "        self.linear_log_var = nn.Linear(hidden_size, latent_size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = x.view(-1, 784)\n",
        "        \n",
        "        features = self.fc(x)\n",
        "        mu = self.linear_mu(features)\n",
        "        log_var = self.linear_log_var(features)\n",
        "        \n",
        "        return mu, log_var"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG8X7wtShPsU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderFC(nn.Module):\n",
        "    \n",
        "    def __init__(self, latent_size=10):\n",
        "        \n",
        "        super(DecoderFC, self).__init__()\n",
        "        \n",
        "        self.latent_size = latent_size\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(latent_size, hidden_size, bias=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(hidden_size, hidden_size, bias=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(hidden_size, 784)\n",
        "            \n",
        "        )\n",
        "        \n",
        "        \n",
        "        self.sigmoid =  nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, z):\n",
        "        \n",
        "        x = self.fc(z)\n",
        "        \n",
        "        x = self.sigmoid(x)\n",
        "        \n",
        "        return x.view(-1, 1, 28, 28)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJFAv-4gzBZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weight_init(m):\n",
        "    \n",
        "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
        "        m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n",
        "        m.weight.data.requires_grad = True\n",
        "        \n",
        "        try:\n",
        "            m.bias.data = torch.zeros(m.bias.data.size(), requires_grad=True)\n",
        "        except AttributeError:\n",
        "            pass\n",
        "    elif isinstance(m, nn.BatchNorm2d):\n",
        "        m.weight.data = torch.ones(m.weight.data.size(), requires_grad=True)\n",
        "        m.bias.data = torch.zeros(m.bias.data.size(), requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8evZ470aoEp0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = EncoderFC(latent_size)\n",
        "encoder.apply(weight_init)\n",
        "encoder = encoder.to(device)\n",
        "\n",
        "decoder = DecoderFC(latent_size)\n",
        "decoder.apply(weight_init)\n",
        "decoder = decoder.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4DesJcKp6uV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_step(batch_X, batch_y, criterion, optimizer_e, optimizer_d):\n",
        "    \n",
        "    optimizer_e.zero_grad()\n",
        "    optimizer_d.zero_grad()\n",
        "    \n",
        "    x = torch.FloatTensor(batch_X).to(device)\n",
        "    labels = torch.LongTensor(batch_y)\n",
        "    \n",
        "    # Predictive mean and log variance\n",
        "    # Data in the range of -1 to 1\n",
        "    # mu, log_var = encoder((x - 0.5) / 0.5)\n",
        "    mu, log_var = encoder(x)\n",
        "    \n",
        "    # Sample i.e. the reparameterization trick\n",
        "    # var = e^log_var\n",
        "    # std = sqrt(var)\n",
        "    # std = e^(log(var)/2)\n",
        "    z = mu + torch.randn_like(mu) * torch.exp(log_var / 2.)\n",
        "    \n",
        "    # Decode the sampled vector\n",
        "    x_reconstructed = decoder(z)\n",
        "    \n",
        "    # Recostruction loss\n",
        "    # Use binary crossentropy loss\n",
        "    reconstruction_loss = criterion(x_reconstructed, x)\n",
        "    # reconstruction_loss = criterion(x_reconstructed, (x-0.5)/0.5)\n",
        "    \n",
        "    # KL divergence between prior p_theta(z) over z and posterior q_phi(z|x)\n",
        "    # Appendix B: Kingma and Welling, Autoencoding Variational Bayes.\n",
        "    # https://arxiv.org/abs/1312.6114\n",
        "    kl_divergence = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "    \n",
        "    loss = (reconstruction_loss + kl_divergence) / batch_X.shape[0]\n",
        "    \n",
        "    loss.backward()\n",
        "    \n",
        "    optimizer_e.step()\n",
        "    optimizer_d.step()\n",
        "    \n",
        "    return reconstruction_loss.item(), kl_divergence.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8itIosQ_cQh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(X, y, criterion, optimizer_e, optimizer_d, batch_size=128):\n",
        "    \n",
        "    ptr = 0\n",
        "    n_steps = X.shape[0] // batch_size + (X.shape[0]%batch_size != 0)\n",
        "    \n",
        "    reconstruction_loss = 0.\n",
        "    kl_divergence = 0.\n",
        "    for _iter in range(n_steps):\n",
        "        _X, _y = X[ptr:ptr+batch_size, ...], y[ptr:ptr+batch_size]\n",
        "        _reconstruction_loss, _kl_divergence = train_step(_X, _y, criterion, optimizer_e, optimizer_d)\n",
        "        \n",
        "        reconstruction_loss += _reconstruction_loss\n",
        "        kl_divergence += _kl_divergence\n",
        "        \n",
        "    return reconstruction_loss / np.prod(X.shape), kl_divergence / (X.shape[0] * latent_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzU6vh1lLxPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def val_step(batch_X, batch_y, criterion):\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        x = torch.FloatTensor(batch_X).to(device)\n",
        "        labels = torch.LongTensor(batch_y)\n",
        "\n",
        "        # Predictive mean and log variance\n",
        "        mu, log_var = encoder(x)\n",
        "\n",
        "        # Sample i.e. the reparameterization trick\n",
        "        # var = e^log_var\n",
        "        # std = sqrt(var)\n",
        "        # std = e^(log(var)/2)\n",
        "        z = mu + torch.randn_like(mu) * torch.exp(log_var / 2.)\n",
        "\n",
        "        # Decode the sampled vector\n",
        "        x_reconstructed = decoder(z)\n",
        "\n",
        "        # Recostruction loss\n",
        "        # Use binary crossentropy loss\n",
        "        reconstruction_loss = criterion(x_reconstructed, x)\n",
        "        # reconstruction_loss = criterion(x_reconstructed, (x-0.5)/0.5)\n",
        "\n",
        "        # KL divergence between prior p_theta(z) over z and posterior q_phi(z|x)\n",
        "        # Appendix B: Kingma and Welling, Autoencoding Variational Bayes.\n",
        "        # https://arxiv.org/abs/1312.6114\n",
        "        kl_divergence = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "    \n",
        "    return reconstruction_loss.item(), kl_divergence.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAlZW1R7eIum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def val_epoch(X, y, criterion, batch_size=128):\n",
        "    \n",
        "    ptr = 0\n",
        "    n_steps = X.shape[0] // batch_size + (X.shape[0]%batch_size != 0)\n",
        "    \n",
        "    reconstruction_loss = 0.\n",
        "    kl_divergence = 0.\n",
        "    for _iter in range(n_steps):\n",
        "        _X, _y = X[ptr:ptr+batch_size, ...], y[ptr:ptr+batch_size]\n",
        "        _reconstruction_loss, _kl_divergence = val_step(_X, _y, criterion)\n",
        "        \n",
        "        reconstruction_loss += _reconstruction_loss\n",
        "        kl_divergence += _kl_divergence\n",
        "        \n",
        "    return reconstruction_loss / np.prod(X.shape), kl_divergence / (X.shape[0] * latent_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8WXKuAtOC7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize(noise):\n",
        "    \n",
        "    \"\"\"noise: torch Tensor\n",
        "    \"\"\"\n",
        "    \n",
        "    n_images = noise.size(0)\n",
        "    \n",
        "    rows = int(np.sqrt(n_images))\n",
        "    cols = rows\n",
        "    \n",
        "    grid = np.zeros((rows*28, cols*28), dtype=np.uint8)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        _x = decoder(noise)\n",
        "        \n",
        "    images = _x.cpu().numpy()\n",
        "    \n",
        "    ptr = 0\n",
        "    for i in range(rows):\n",
        "        _row = i * 28\n",
        "        for j in range(cols):\n",
        "            _col = j * 28\n",
        "            img = images[ptr]\n",
        "            if img.shape[0] == 1:\n",
        "                img = np.squeeze(img, axis=0)\n",
        "            else:\n",
        "                img = np.transpose(img, axes=(1, 2, 0))\n",
        "            img = (img * 255.).astype(np.uint8)\n",
        "            grid[_row:_row+28, _col:_col+28] = img\n",
        "            ptr += 1\n",
        "            \n",
        "    cmap = 'gray' if np.ndim(img) == 2 else None\n",
        "    plt.imshow(grid, cmap=cmap)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPxqelU3MSYv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyn0_BpoNw57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = 1. - np.expand_dims(X_train, axis=1) / 255.\n",
        "X_test = 1. - np.expand_dims(X_test, axis=1) / 255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_UAii0nNzjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fixed_noise_vector = torch.FloatTensor(64, latent_size).normal_(0., 1.)\n",
        "if 'cuda' in device:\n",
        "    fixed_noise_vector = fixed_noise_vector.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWxJYdviQ3kB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer_e = optim.Adam(encoder.parameters(), lr=1e-4)\n",
        "optimizer_d = optim.Adam(decoder.parameters(), lr=1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urs2aCYye1iL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCELoss(reduction='sum')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tehs_Q0liuyZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    train_indices = np.random.permutation(X_train.shape[0])\n",
        "    _X_train = X_train[train_indices]\n",
        "    _y_train = y_train[train_indices]\n",
        "\n",
        "    test_indices = np.random.permutation(X_test.shape[0])\n",
        "    _X_test = X_test[test_indices]\n",
        "    _y_test = y_test[test_indices]\n",
        "    \n",
        "    train_reconstruction_loss, train_kl_divergence = train_epoch(_X_train, _y_train, criterion, optimizer_e, optimizer_d, batch_size=batch_size)\n",
        "    print('Train: Epoch: {} | BCE: {:.5f} | KL Divergence: {:.5f}'.format(epoch, train_reconstruction_loss, train_kl_divergence))\n",
        "    val_reconstruction_loss, val_kl_divergence = val_epoch(_X_test, _y_test, criterion, batch_size)\n",
        "    print('Val: Epoch: {} | BCE: {:.5f} | KL Divergence: {:.5f}'.format(epoch, val_reconstruction_loss, val_kl_divergence))\n",
        "    \n",
        "    if epoch % 10 == 0:\n",
        "        visualize(fixed_noise_vector)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNAOCjJRKAD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dec = decoder.eval().to(device)\n",
        "enc = encoder.eval().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TL1p3JUSlotK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def interpolate(X, y, from_digit=1, to_digit=0, steps=30, enc=None, dec=None):\n",
        "    \"\"\"\n",
        "    Interpolate from one digit to another\n",
        "    \"\"\"\n",
        "    idx = int(np.random.randint(0, 100))\n",
        "    X_from = X[y == from_digit][52]\n",
        "    X_to = X[y == to_digit][52]\n",
        "    \n",
        "    X_from = torch.FloatTensor(np.expand_dims(X_from, axis=0)).to(device)\n",
        "    X_to = torch.FloatTensor(np.expand_dims(X_to, axis=0)).to(device)\n",
        "    \n",
        "    mu_from, log_var_from = enc(X_from)\n",
        "    mu_to, log_var_to = enc(X_to)\n",
        "    \n",
        "    z_from = mu_from + torch.randn_like(mu_from) * torch.exp(log_var_from / 2.)\n",
        "    z_to = mu_to + torch.randn_like(mu_to) * torch.exp(log_var_to / 2.)\n",
        "    \n",
        "    grid = np.zeros((28, 28*steps), dtype=np.uint8)\n",
        "    \n",
        "    images = []\n",
        "    for eps in np.linspace(0., 1., steps):\n",
        "        z = z_from + (z_to - z_from) * eps\n",
        "        image = dec(z.unsqueeze(0))\n",
        "        images.append(image.detach().cpu().numpy())\n",
        "        \n",
        "    for i, img in enumerate(images):\n",
        "        _img = img[0] * 255.\n",
        "        _img = _img.astype(np.uint8)\n",
        "        \n",
        "        grid[:, i*28:i*28+28] = _img\n",
        "        \n",
        "    f = plt.figure(figsize=(20, 20))\n",
        "    plt.imshow(grid, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    return images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gjG5dQwCxBR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def interpolate_multiple(X, y, from_digit=1, to_digit1=0, to_digit2=7, steps=10, enc=None, dec=None):\n",
        "    \"\"\"\n",
        "    Interpolate from one digit to another, then to another\n",
        "    \"\"\"\n",
        "    X_from = X[y == from_digit][8] # Any random index\n",
        "    X_to1 = X[y == to_digit1][89]\n",
        "    X_to2 = X[y == to_digit2][56]\n",
        "    \n",
        "    X_from = torch.FloatTensor(np.expand_dims(X_from, axis=0)).to(device)\n",
        "    X_to1 = torch.FloatTensor(np.expand_dims(X_to1, axis=0)).to(device)\n",
        "    X_to2 = torch.FloatTensor(np.expand_dims(X_to2, axis=0)).to(device)\n",
        "    \n",
        "    mu_from, log_var_from = enc(X_from)\n",
        "    mu_to1, log_var_to1 = enc(X_to1)\n",
        "    mu_to2, log_var_to2 = enc(X_to2)\n",
        "    \n",
        "    z_from = mu_from + torch.randn_like(mu_from) * torch.exp(log_var_from / 2.)\n",
        "    z_to1 = mu_to1 + torch.randn_like(mu_to1) * torch.exp(log_var_to1 / 2.)\n",
        "    z_to2 = mu_to2 + torch.randn_like(mu_to2) * torch.exp(log_var_to2 / 2.)\n",
        "    \n",
        "    grid = np.zeros((28, 28*steps*2 - 28), dtype=np.uint8)\n",
        "    \n",
        "    images = []\n",
        "    for eps in np.linspace(0., 1., steps):\n",
        "        z1 = z_from + (z_to1 - z_from) * eps\n",
        "        \n",
        "        image = dec(z1.unsqueeze(0))\n",
        "        images.append(image.detach().cpu().numpy())\n",
        "        \n",
        "    for idx, eps in enumerate(np.linspace(0., 1., steps)):\n",
        "        if idx == 0:\n",
        "            continue\n",
        "        z2 = (z_to1 + (z_to2 - z_to1) * eps)\n",
        "        image = dec(z2.unsqueeze(0))\n",
        "        images.append(image.detach().cpu().numpy())\n",
        "\n",
        "    for i, img in enumerate(images):\n",
        "        _img = img[0] * 255.\n",
        "        _img = _img.astype(np.uint8)\n",
        "        \n",
        "        grid[:, i*28:i*28+28] = _img\n",
        "        \n",
        "    f = plt.figure(figsize=(20, 20))\n",
        "    plt.imshow(grid, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    return images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRNKF5EZYdF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def interpolate_multiple2(X, y, from_digit=1, to_digit1=0, to_digit2=7, steps=10, enc=None, dec=None):\n",
        "    \"\"\"\n",
        "    Interpolate from one digit to another, then to another, and back to the starting digit\n",
        "    \"\"\"\n",
        "\n",
        "    X_from = X[y == from_digit][80] # Any random index\n",
        "    X_to1 = X[y == to_digit1][72]\n",
        "    X_to2 = X[y == to_digit2][67]\n",
        "    \n",
        "    X_from = torch.FloatTensor(np.expand_dims(X_from, axis=0)).to(device)\n",
        "    X_to1 = torch.FloatTensor(np.expand_dims(X_to1, axis=0)).to(device)\n",
        "    X_to2 = torch.FloatTensor(np.expand_dims(X_to2, axis=0)).to(device)\n",
        "    \n",
        "    mu_from, log_var_from = enc(X_from)\n",
        "    mu_to1, log_var_to1 = enc(X_to1)\n",
        "    mu_to2, log_var_to2 = enc(X_to2)\n",
        "    \n",
        "    z_from = mu_from + torch.randn_like(mu_from) * torch.exp(log_var_from / 2.)\n",
        "    z_to1 = mu_to1 + torch.randn_like(mu_to1) * torch.exp(log_var_to1 / 2.)\n",
        "    z_to2 = mu_to2 + torch.randn_like(mu_to2) * torch.exp(log_var_to2 / 2.)\n",
        "    \n",
        "    grid = np.zeros((28, 28*steps*3 - 2*28), dtype=np.uint8)\n",
        "    \n",
        "    images = []\n",
        "    for eps in np.linspace(0., 1., steps):\n",
        "        z1 = z_from + (z_to1 - z_from) * eps\n",
        "        \n",
        "        image = dec(z1.unsqueeze(0))\n",
        "        images.append(image.detach().cpu().numpy())\n",
        "        \n",
        "    for idx, eps in enumerate(np.linspace(0., 1., steps)):\n",
        "        if idx == 0:\n",
        "            continue\n",
        "        z2 = (z_to1 + (z_to2 - z_to1) * eps)\n",
        "        image = dec(z2.unsqueeze(0))\n",
        "        images.append(image.detach().cpu().numpy())\n",
        "\n",
        "    for idx, eps in enumerate(np.linspace(0., 1., steps)):\n",
        "        if idx == 0:\n",
        "            continue\n",
        "        z4 = (z_to2 + (z_from - z_to2) * eps)\n",
        "        image = dec(z4.unsqueeze(0))\n",
        "        images.append(image.detach().cpu().numpy())\n",
        "\n",
        "    for i, img in enumerate(images):\n",
        "        _img = img[0] * 255.\n",
        "        _img = _img.astype(np.uint8)\n",
        "        \n",
        "        grid[:, i*28:i*28+28] = _img\n",
        "        \n",
        "    f = plt.figure(figsize=(20, 20))\n",
        "    plt.imshow(grid, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    return images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07RzSEQMwCve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in [9]:\n",
        "    imgs = interpolate(X_test, y_test, from_digit=1, to_digit=i, steps=150, enc=enc, dec=dec)\n",
        "    # Uncomment to save as a gif\n",
        "    # imageio.mimwrite(base_path + 'b_interpolation_{}to{}.gif'.format(1, i), [(ing[0, 0, :, :] * 255.).astype(np.uint8) for ing in imgs], fps=15)\n",
        "    # imageio.mimwrite(base_path + 'w_interpolation_{}to{}.gif'.format(1, i), [((1. - ing[0, 0, :, :]) * 255.).astype(np.uint8) for ing in imgs], fps=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibBgQ0VXFsv2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imgs = interpolate_multiple(X_test, y_test, from_digit=4, to_digit1=9, \n",
        "                            to_digit2=1, steps=25, \n",
        "                            enc=enc, dec=dec)\n",
        "# Uncomment to save as gif\n",
        "# imageio.mimwrite(base_path + 'vae_interpolation_loop.gif', [(imgs[0, 0, :, :] * 255.).astype(np.uint8) for img in imgs], fps=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPYT1-CNJKKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JktkH0DIY3SP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imgs2 = interpolate_multiple2(X_test, y_test, from_digit=1, to_digit1=0, \n",
        "                            to_digit2=9, steps=75, \n",
        "                            enc=enc, dec=dec)\n",
        "# Uncomment to save as gif\n",
        "# imageio.mimwrite(base_path + 'vae_interpolation_loop_v5.gif', [(ing[0, 0, :, :] * 255.).astype(np.uint8) for ing in imgs2], fps=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxQjcS_IZsP1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gWgJJaHuGUY",
        "colab_type": "text"
      },
      "source": [
        "# Jitter Experiments:\n",
        "See what happens when we perturb one of the latent dimensions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaPd-XXauO5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perturb(X, y, steps=10, dec=None, save=False):\n",
        "    \"\"\"\n",
        "    We can generate the entire grid as a batch. This is not feasible for large\n",
        "    number of steps\n",
        "    \"\"\"\n",
        "    # Generate samples from the support of p(z)\n",
        "    x = norm.ppf(np.linspace(0.05, 0.95, num=steps))\n",
        "    y = norm.ppf(np.linspace(0.05, 0.95, num=steps))\n",
        "    l_x = x.shape[0]\n",
        "    l_y = y.shape[0]\n",
        "    x_grid = np.repeat(x, l_y).reshape(-1, 1)\n",
        "    y_grid = np.tile(y, l_x).reshape(-1, 1)\n",
        "    _z = np.concatenate([x_grid, y_grid], axis=1)\n",
        "\n",
        "    z = torch.from_numpy(_z).float().to(device)\n",
        "    \n",
        "    grid = np.zeros((28*x.shape[0], 28*y.shape[0]), dtype=np.uint8)\n",
        "    \n",
        "    images = dec(z).detach().cpu().numpy()\n",
        "    \n",
        "    ptr = 0\n",
        "    for i, _x in enumerate(x):\n",
        "        for j, _y in enumerate(y):\n",
        "        \n",
        "            img = images[ptr, 0, ...]\n",
        "            _img = img * 255.\n",
        "            _img = _img.astype(np.uint8)\n",
        "            \n",
        "            grid[i*28:i*28+28, j*28:j*28+28] = _img\n",
        "\n",
        "            ptr += 1\n",
        "        \n",
        "    f = plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(grid, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    if save:\n",
        "        grid_img = Image.fromarray(grid)\n",
        "        grid_img.save(base_path + 'vae_mnist_manifold.png')\n",
        "        grid_img.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS5x4sWSNQKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perturb_iterative(X, y, steps=10, dec=None, save=False):\n",
        "    \"\"\"\n",
        "    For a large number of steps, generate the grid iteratively\n",
        "    \"\"\"\n",
        "    # Generate samples from the support of p(z)\n",
        "    x = norm.ppf(np.linspace(0.05, 0.95, num=steps))\n",
        "    y = norm.ppf(np.linspace(0.05, 0.95, num=steps))\n",
        "    l_x = x.shape[0]\n",
        "    l_y = y.shape[0]\n",
        "    x_grid = np.repeat(x, l_y).reshape(-1, 1)\n",
        "    y_grid = np.tile(y, l_x).reshape(-1, 1)\n",
        "    _z = np.concatenate([x_grid, y_grid], axis=1)\n",
        "    \n",
        "    grid = np.zeros((28*x.shape[0], 28*y.shape[0]), dtype=np.uint8)\n",
        "    n_rows, n_cols = grid.shape\n",
        "\n",
        "    images_l = []\n",
        "    for k in range(_z.shape[0]):\n",
        "        z = torch.from_numpy(_z[k]).unsqueeze(dim=0).float().to(device)\n",
        "        images_l.append(dec(z).detach().cpu().numpy())\n",
        "    \n",
        "    ptr = 0\n",
        "    for i, _x in enumerate(x): # -1, -1, ..0, 0, \n",
        "        for j, _x in enumerate(x): # -1, 0, 1,\n",
        "        \n",
        "            img = images_l[ptr][0, ...]\n",
        "            _img = img * 255.\n",
        "            _img = _img.astype(np.uint8)\n",
        "            \n",
        "            grid[n_rows-(j*28+28):n_rows-j*28, i*28:i*28+28] = _img\n",
        "\n",
        "            ptr += 1\n",
        "        \n",
        "    f = plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(grid, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    if save:\n",
        "        grid_img = Image.fromarray(grid)\n",
        "        grid_img.save(base_path + 'vae_mnist_manifold_{}_v3.png'.format(steps))\n",
        "        grid_img.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xewyEU5Hyd9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "perturb_iterative(X_test, y_test, steps=10, dec=decoder, save=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLGmjcsAysda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_latent(X, y, enc, samples_per_class=10):\n",
        "\n",
        "    \"\"\"\n",
        "    Plot the transformed samples from the test set\n",
        "    \"\"\"\n",
        "\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "\n",
        "    for digit in range(10):\n",
        "\n",
        "        # Draw 10 random samples\n",
        "        _X = X[y == digit]\n",
        "        _y = y[y == digit]\n",
        "        indices = np.random.permutation(np.arange(_X.shape[0]))\n",
        "        _X = _X[indices[:samples_per_class]]\n",
        "\n",
        "        X_sample = torch.from_numpy(_X).float().to(device)\n",
        "\n",
        "        mu, log_var = enc(X_sample)\n",
        "        z = (mu + torch.randn_like(mu) * torch.exp(log_var / 2.)).detach().cpu().numpy()\n",
        "\n",
        "        plt.scatter(z[:, 0], z[:, 1], c=None, alpha=0.7)\n",
        "    plt.legend([_ for _ in range(10)])\n",
        "    plt.xlabel('z1')\n",
        "    plt.ylabel('z2')\n",
        "    # plt.savefig(base_path + '/vae_latent_plot_v3.png', dpi=300)\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujkrJTi0-F2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the transformed samples from the test set\n",
        "plot_latent(X_test, y_test, encoder, samples_per_class=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgNXbG5U-JWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}