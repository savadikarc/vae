{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "conditional_vae.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/savadikarc/vae/blob/master/conditional_vae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GcAj7PUVT3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIe5EibsVes6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_path = '/content/drive/My Drive/DL_ML/VAE/Images_CVAE/'\n",
        "!ls /content/drive/My\\ Drive/DL_ML/VAE/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHu3L_OQUYRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# NumPy, standard\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Visualization\n",
        "import imageio\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgAh-TN3Z3ud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist, cifar10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVwt1OB3kw10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "latent_size = 2 #15\n",
        "hidden_size = 1024\n",
        "base_filters = 8\n",
        "batch_size = 2048\n",
        "EPOCHS = 1000\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IexwMpwgg4Db",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderFC(nn.Module):\n",
        "    \n",
        "    def __init__(self, latent_size=10):\n",
        "        \n",
        "        super(EncoderFC, self).__init__()\n",
        "        self.latent_size = latent_size\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(784+10, hidden_size, bias=True),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        \n",
        "        self.linear_mu = nn.Linear(hidden_size, latent_size)\n",
        "        self.linear_log_var = nn.Linear(hidden_size, latent_size)\n",
        "        \n",
        "    def forward(self, x, condition_vector):\n",
        "        \n",
        "        x = x.view(-1, 784)\n",
        "        x = torch.cat([x, condition_vector], dim=1)\n",
        "        \n",
        "        features = self.fc(x)\n",
        "        mu = self.linear_mu(features)\n",
        "        log_var = self.linear_log_var(features)\n",
        "        \n",
        "        return mu, log_var"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG8X7wtShPsU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderFC(nn.Module):\n",
        "    \n",
        "    def __init__(self, latent_size=10):\n",
        "        \n",
        "        super(DecoderFC, self).__init__()\n",
        "        \n",
        "        self.latent_size = latent_size\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(latent_size+10, hidden_size, bias=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(hidden_size, 784)\n",
        "            \n",
        "        )\n",
        "        \n",
        "        \n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, z):\n",
        "        \n",
        "        x = self.fc(z)\n",
        "        \n",
        "        x = self.sigmoid(x)\n",
        "        \n",
        "        return x.view(-1, 1, 28, 28)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJFAv-4gzBZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weight_init(m):\n",
        "    \n",
        "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
        "        m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n",
        "        m.weight.data.requires_grad = True\n",
        "        \n",
        "        try:\n",
        "            m.bias.data = torch.zeros(m.bias.data.size(), requires_grad=True)\n",
        "        except AttributeError:\n",
        "            pass\n",
        "    elif isinstance(m, nn.BatchNorm2d):\n",
        "        m.weight.data = torch.ones(m.weight.data.size(), requires_grad=True)\n",
        "        m.bias.data = torch.zeros(m.bias.data.size(), requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8evZ470aoEp0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = EncoderFC(latent_size)\n",
        "encoder.apply(weight_init)\n",
        "encoder = encoder.to(device)\n",
        "\n",
        "decoder = DecoderFC(latent_size)\n",
        "decoder.apply(weight_init)\n",
        "decoder = decoder.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4DesJcKp6uV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_step(batch_X, batch_y, criterion, optimizer_e, optimizer_d):\n",
        "    \n",
        "    optimizer_e.zero_grad()\n",
        "    optimizer_d.zero_grad()\n",
        "    \n",
        "    condition = np.zeros((batch_y.shape[0], 10))\n",
        "    condition[np.arange(batch_y.shape[0]), batch_y] = 1.\n",
        "    condition_vector = torch.from_numpy(condition).float().to(device)\n",
        "\n",
        "    x = torch.FloatTensor(batch_X).to(device)\n",
        "    \n",
        "    # Predictive mean and log variance\n",
        "    mu, log_var = encoder(x, condition_vector)\n",
        "    \n",
        "    # Sample i.e. the reparameterization trick\n",
        "    # var = e^log_var\n",
        "    # std = sqrt(var)\n",
        "    # std = e^(log(var)/2)\n",
        "    _z = mu + torch.randn_like(mu) * torch.exp(log_var / 2.)\n",
        "    z = torch.cat([_z, condition_vector], dim=1)\n",
        "    \n",
        "    # Decode the sampled vector\n",
        "    x_reconstructed = decoder(z)\n",
        "    \n",
        "    # Recostruction loss\n",
        "    # Use binary crossentropy loss\n",
        "    reconstruction_loss = criterion(x_reconstructed, x)\n",
        "    \n",
        "    # KL divergence between prior p_theta(z) over z and posterior q_phi(z|x)\n",
        "    # Appendix B: Kingma and Welling, Autoencoding Variational Bayes.\n",
        "    # https://arxiv.org/abs/1312.6114\n",
        "    kl_divergence = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "    \n",
        "    loss = (reconstruction_loss + kl_divergence) / batch_X.shape[0]\n",
        "    \n",
        "    loss.backward()\n",
        "    \n",
        "    optimizer_e.step()\n",
        "    optimizer_d.step()\n",
        "    \n",
        "    return reconstruction_loss.item(), kl_divergence.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8itIosQ_cQh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(X, y, criterion, optimizer_e, optimizer_d, batch_size=128):\n",
        "    \n",
        "    ptr = 0\n",
        "    n_steps = X.shape[0] // batch_size + (X.shape[0]%batch_size != 0)\n",
        "    \n",
        "    reconstruction_loss = 0.\n",
        "    kl_divergence = 0.\n",
        "    for _iter in range(n_steps):\n",
        "        _X, _y = X[ptr:ptr+batch_size, ...], y[ptr:ptr+batch_size]\n",
        "        _reconstruction_loss, _kl_divergence = train_step(_X, _y, criterion, optimizer_e, optimizer_d)\n",
        "        \n",
        "        reconstruction_loss += _reconstruction_loss\n",
        "        kl_divergence += _kl_divergence\n",
        "        \n",
        "    return reconstruction_loss / np.prod(X.shape), kl_divergence / (X.shape[0] * latent_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzU6vh1lLxPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def val_step(batch_X, batch_y, criterion):\n",
        "    \n",
        "    with torch.no_grad():\n",
        "\n",
        "        condition = np.zeros((batch_y.shape[0], 10))\n",
        "        condition[np.arange(batch_y.shape[0]), batch_y] = 1.\n",
        "        condition_vector = torch.from_numpy(condition).float().to(device)\n",
        "\n",
        "        x = torch.FloatTensor(batch_X).to(device)\n",
        "\n",
        "        # Predictive mean and log variance\n",
        "        mu, log_var = encoder(x, condition_vector)\n",
        "\n",
        "        # Sample i.e. the reparameterization trick\n",
        "        # var = e^log_var\n",
        "        # std = sqrt(var)\n",
        "        # std = e^(log(var)/2)\n",
        "        _z = mu + torch.randn_like(mu) * torch.exp(log_var / 2.)\n",
        "        z = torch.cat([_z, condition_vector], dim=1)\n",
        "\n",
        "        # Decode the sampled vector\n",
        "        x_reconstructed = decoder(z)\n",
        "\n",
        "        # Recostruction loss\n",
        "        # Use binary crossentropy loss\n",
        "        reconstruction_loss = criterion(x_reconstructed, x)\n",
        "\n",
        "        # KL divergence between prior p_theta(z) over z and posterior q_phi(z|x)\n",
        "        # Appendix B: Kingma and Welling, Autoencoding Variational Bayes.\n",
        "        # https://arxiv.org/abs/1312.6114\n",
        "        kl_divergence = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "    \n",
        "    return reconstruction_loss.item(), kl_divergence.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAlZW1R7eIum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def val_epoch(X, y, criterion, batch_size=128):\n",
        "    \n",
        "    ptr = 0\n",
        "    n_steps = X.shape[0] // batch_size + (X.shape[0]%batch_size != 0)\n",
        "    \n",
        "    reconstruction_loss = 0.\n",
        "    kl_divergence = 0.\n",
        "    for _iter in range(n_steps):\n",
        "        _X, _y = X[ptr:ptr+batch_size, ...], y[ptr:ptr+batch_size]\n",
        "        _reconstruction_loss, _kl_divergence = val_step(_X, _y, criterion)\n",
        "        \n",
        "        reconstruction_loss += _reconstruction_loss\n",
        "        kl_divergence += _kl_divergence\n",
        "        \n",
        "    return reconstruction_loss / np.prod(X.shape), kl_divergence / (X.shape[0] * latent_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8WXKuAtOC7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize(noise):\n",
        "    \n",
        "    \"\"\"noise: torch Tensor\n",
        "    \"\"\"\n",
        "    \n",
        "    n_images = noise.size(0)\n",
        "    \n",
        "    rows = 10\n",
        "    cols = 8\n",
        "    \n",
        "    grid = np.zeros((rows*28, cols*28), dtype=np.uint8)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        _x = decoder(noise)\n",
        "        \n",
        "    images = _x.cpu().numpy()\n",
        "    \n",
        "    ptr = 0\n",
        "    for i in range(rows):\n",
        "        _row = i * 28\n",
        "        for j in range(cols):\n",
        "            _col = j * 28\n",
        "            img = images[ptr]\n",
        "            if img.shape[0] == 1:\n",
        "                img = np.squeeze(img, axis=0)\n",
        "            else:\n",
        "                img = np.transpose(img, axes=(1, 2, 0))\n",
        "            img = (img * 255.).astype(np.uint8)\n",
        "            grid[_row:_row+28, _col:_col+28] = img\n",
        "            ptr += 1\n",
        "            \n",
        "    cmap = 'gray' if np.ndim(img) == 2 else None\n",
        "    plt.imshow(grid, cmap=cmap)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPxqelU3MSYv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyn0_BpoNw57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.expand_dims(X_train, axis=1) / 255.\n",
        "X_test = np.expand_dims(X_test, axis=1) / 255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_UAii0nNzjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noise_vector = torch.FloatTensor(8, latent_size).normal_(0., 1.).repeat(10, 1)\n",
        "condition = np.zeros((80, 10))\n",
        "condition[np.arange(80), np.repeat(np.arange(10), 8)] = 1.\n",
        "condition_vector = torch.from_numpy(condition).float()\n",
        "fixed_noise_vector = torch.cat([noise_vector, condition_vector], dim=1)\n",
        "if 'cuda' in device:\n",
        "    fixed_noise_vector = fixed_noise_vector.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWxJYdviQ3kB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer_e = optim.Adam(encoder.parameters(), lr=1e-4)\n",
        "optimizer_d = optim.Adam(decoder.parameters(), lr=1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urs2aCYye1iL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCELoss(reduction='sum')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tehs_Q0liuyZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    train_indices = np.random.permutation(X_train.shape[0])\n",
        "    _X_train = X_train[train_indices]\n",
        "    _y_train = y_train[train_indices]\n",
        "\n",
        "    test_indices = np.random.permutation(X_test.shape[0])\n",
        "    _X_test = X_test[test_indices]\n",
        "    _y_test = y_test[test_indices]\n",
        "    \n",
        "    train_reconstruction_loss, train_kl_divergence = train_epoch(_X_train, _y_train, criterion, optimizer_e, optimizer_d, batch_size=batch_size)\n",
        "    print('Train: Epoch: {} | BCE: {:.5f} | KL Divergence: {:.5f}'.format(epoch, train_reconstruction_loss, train_kl_divergence))\n",
        "    val_reconstruction_loss, val_kl_divergence = val_epoch(_X_test, _y_test, criterion, batch_size)\n",
        "    print('Val: Epoch: {} | BCE: {:.5f} | KL Divergence: {:.5f}'.format(epoch, val_reconstruction_loss, val_kl_divergence))\n",
        "    \n",
        "    if epoch % 10 == 0:\n",
        "        visualize(fixed_noise_vector)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNAOCjJRKAD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dec = decoder.eval().to(device)\n",
        "enc = encoder.eval().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gWgJJaHuGUY",
        "colab_type": "text"
      },
      "source": [
        "# Jitter Experiments:\n",
        "See what happens when we perturb one of the latent dimensions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaPd-XXauO5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perturb(X, y, steps=30, digit=0, dec=None, save=False):\n",
        "\n",
        "    # Generate samples from the support of p(z)\n",
        "    x = norm.ppf(np.linspace(0.05, 0.95, num=steps))\n",
        "    y = norm.ppf(np.linspace(0.05, 0.95, num=steps))\n",
        "    l_x = x.shape[0]\n",
        "    l_y = y.shape[0]\n",
        "    x_grid = np.repeat(x, l_y).reshape(-1, 1)\n",
        "    y_grid = np.tile(y, l_x).reshape(-1, 1)\n",
        "    _z = np.concatenate([x_grid, y_grid], axis=1)\n",
        "\n",
        "    condition = np.zeros((_z.shape[0], 10))\n",
        "    condition[np.arange(_z.shape[0]), digit] = 1.\n",
        "\n",
        "    images_l = []\n",
        "    for k in range(_z.shape[0]):\n",
        "        _z_ = np.expand_dims(_z[k], axis=0)\n",
        "        _condition = np.expand_dims(condition[k], axis=0)\n",
        "        z = torch.cat([torch.from_numpy(_z_).float(), torch.from_numpy(_condition).float()], dim=1).to(device)\n",
        "        images_l.append(dec(z).detach().cpu().numpy())\n",
        "\n",
        "    \n",
        "    grid = np.zeros((28*x.shape[0], 28*y.shape[0]), dtype=np.uint8)\n",
        "    n_rows, n_cols = grid.shape\n",
        "    \n",
        "    ptr = 0\n",
        "    for i, _x in enumerate(x): # -1, -1, ..0, 0, \n",
        "        for j, _y in enumerate(y): # -1, 0, 1,\n",
        "        \n",
        "            img = images_l[ptr][0, ...]\n",
        "            _img = img * 255.\n",
        "            _img = _img.astype(np.uint8)\n",
        "            \n",
        "            grid[n_rows-(j*28+28):n_rows-j*28, i*28:i*28+28] = _img\n",
        "\n",
        "            ptr += 1\n",
        "        \n",
        "    f = plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(grid, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    if save:\n",
        "        grid_img = Image.fromarray(grid)\n",
        "        grid_img.save(base_path + 'conditional_vae_mnist_manifold_{}.png'.format(digit))\n",
        "        grid_img.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xewyEU5Hyd9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for digit in range(10):\n",
        "    perturb(X_test, y_test, steps=10, digit=digit, dec=decoder, save=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLGmjcsAysda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_latent(X, y, enc, samples_per_class=10):\n",
        "\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "\n",
        "    for digit in range(10):\n",
        "\n",
        "        # Draw 10 random samples\n",
        "        _X = X[y == digit]\n",
        "        _y = y[y == digit]\n",
        "        indices = np.random.permutation(np.arange(_X.shape[0]))\n",
        "        _X = _X[indices[:samples_per_class]]\n",
        "        _y = _y[indices[:samples_per_class]]\n",
        "\n",
        "        X_sample = torch.from_numpy(_X).float().to(device)\n",
        "\n",
        "        condition = np.zeros((samples_per_class, 10))\n",
        "        condition[np.arange(samples_per_class), _y] = 1.\n",
        "        condition_vector = torch.from_numpy(condition).float().to(device)\n",
        "\n",
        "        mu, log_var = enc(X_sample, condition_vector)\n",
        "        z = (mu + torch.randn_like(mu) * torch.exp(log_var / 2.)).detach().cpu().numpy()\n",
        "\n",
        "        plt.scatter(z[:, 0], z[:, 1], c=None, alpha=0.7)\n",
        "    plt.legend([_ for _ in range(10)])\n",
        "    plt.xlabel('z1')\n",
        "    plt.ylabel('z2')\n",
        "    plt.savefig(base_path + '/conditional_vae_latent_plot.png', dpi=300)\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujkrJTi0-F2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_latent(X_test, y_test, encoder, samples_per_class=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgNXbG5U-JWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}